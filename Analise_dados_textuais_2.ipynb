{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analise_dados_textuais_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiEBiIJnt0Zk"
      },
      "source": [
        "import nltk\n",
        "from nltk.text import Text\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBtact_K2suE"
      },
      "source": [
        "sents_machado = machado.sents('romance/marm05.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyJJyX8E3yxH"
      },
      "source": [
        "from nltk import tokenize "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8aQQqNk371j"
      },
      "source": [
        "palavras_tokenize = tokenize.word_tokenize(texto, language='portuguese')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX9A7Jy24L22",
        "outputId": "abc20311-984c-4665-9a6c-fc45f96bc48f"
      },
      "source": [
        "palavras_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Existem',\n",
              " 'teorias',\n",
              " 'que',\n",
              " 'defendem',\n",
              " 'que',\n",
              " 'antes',\n",
              " 'das',\n",
              " 'explorações',\n",
              " 'do',\n",
              " 'Império',\n",
              " 'Português',\n",
              " ',',\n",
              " 'houve',\n",
              " 'duas',\n",
              " 'passagens',\n",
              " 'de',\n",
              " 'espanhóis',\n",
              " 'pelo',\n",
              " 'litoral',\n",
              " 'da',\n",
              " 'atual',\n",
              " 'Fortaleza',\n",
              " '.',\n",
              " 'Os',\n",
              " 'navegadores',\n",
              " 'Vicente',\n",
              " 'Yáñez',\n",
              " 'Pinzón',\n",
              " 'e',\n",
              " 'Diego',\n",
              " 'de',\n",
              " 'Lepe',\n",
              " 'teriam',\n",
              " 'desembarcado',\n",
              " 'nas',\n",
              " 'costas',\n",
              " 'cearenses',\n",
              " 'antes',\n",
              " 'da',\n",
              " 'viagem',\n",
              " 'de',\n",
              " 'Pedro',\n",
              " 'Álvares',\n",
              " 'Cabral',\n",
              " 'ao',\n",
              " 'Brasil',\n",
              " 'em',\n",
              " '1500',\n",
              " ',',\n",
              " 'embora',\n",
              " ',',\n",
              " 'na',\n",
              " 'versão',\n",
              " 'tradicional',\n",
              " ',',\n",
              " 'o',\n",
              " 'desembarque',\n",
              " 'de',\n",
              " 'Pinzón',\n",
              " 'tenha',\n",
              " 'se',\n",
              " 'dado',\n",
              " 'no',\n",
              " 'Cabo',\n",
              " 'de',\n",
              " 'Santo',\n",
              " 'Agostinho',\n",
              " 'em',\n",
              " 'Pernambuco',\n",
              " '.',\n",
              " 'Pinzón',\n",
              " 'teria',\n",
              " 'chegado',\n",
              " 'no',\n",
              " 'cabo',\n",
              " 'que',\n",
              " 'se',\n",
              " 'acredita',\n",
              " 'ser',\n",
              " 'o',\n",
              " 'Mucuripe',\n",
              " 'e',\n",
              " 'Lepe',\n",
              " 'aportado',\n",
              " 'na',\n",
              " 'barra',\n",
              " 'do',\n",
              " 'rio',\n",
              " 'Ceará',\n",
              " '.',\n",
              " 'Tais',\n",
              " 'descobertas',\n",
              " 'de',\n",
              " 'território',\n",
              " 'não',\n",
              " 'poderiam',\n",
              " 'ser',\n",
              " 'oficializadas',\n",
              " 'em',\n",
              " 'decorrência',\n",
              " 'do',\n",
              " 'Tratado',\n",
              " 'de',\n",
              " 'Tordesilhas',\n",
              " ',',\n",
              " 'de',\n",
              " '1494',\n",
              " '.',\n",
              " 'A',\n",
              " 'chegada',\n",
              " 'de',\n",
              " 'Pinzón',\n",
              " 'ao',\n",
              " 'Mucuripe',\n",
              " 'foi',\n",
              " ',',\n",
              " 'por',\n",
              " 'várias',\n",
              " 'vezes',\n",
              " ',',\n",
              " 'desconsiderada',\n",
              " 'como',\n",
              " 'um',\n",
              " 'dos',\n",
              " 'possíveis',\n",
              " 'pontos',\n",
              " 'de',\n",
              " 'descobrimento',\n",
              " 'pré-cabralino',\n",
              " 'do',\n",
              " 'país']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQQnv-AJ4Ynk"
      },
      "source": [
        "sentence_tokenize = tokenize.sent_tokenize(texto,language='portuguese')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzaiSja14pwu",
        "outputId": "9f2dd188-6a9d-437c-d507-cf8e1dada7a8"
      },
      "source": [
        "sentence_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Existem teorias que defendem que antes das explorações do Império Português, houve duas passagens de espanhóis pelo litoral da atual Fortaleza.',\n",
              " 'Os navegadores Vicente Yáñez Pinzón e Diego de Lepe teriam desembarcado nas costas cearenses antes da viagem de Pedro Álvares Cabral ao Brasil em 1500, embora, na versão tradicional, o desembarque de Pinzón tenha se dado no Cabo de Santo Agostinho em Pernambuco.',\n",
              " 'Pinzón teria chegado no cabo que se acredita ser o Mucuripe e Lepe aportado na barra do rio Ceará.',\n",
              " 'Tais descobertas de território não poderiam ser oficializadas em decorrência do Tratado de Tordesilhas, de 1494.',\n",
              " 'A chegada de Pinzón ao Mucuripe foi, por várias vezes, desconsiderada como um dos possíveis pontos de descobrimento pré-cabralino do país']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWSIO-YW4uLI"
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxess7z44z6P",
        "outputId": "4e4797d1-b7f7-439a-a2f0-19bf04b6da12"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXsZ469X44Rg"
      },
      "source": [
        "lista_stop = stopwords.words('portuguese')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6FhjjuB5Cju",
        "outputId": "8c06c91b-dc16-40f5-958b-5ebac7e0d4ca"
      },
      "source": [
        "lista_stop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de',\n",
              " 'a',\n",
              " 'o',\n",
              " 'que',\n",
              " 'e',\n",
              " 'é',\n",
              " 'do',\n",
              " 'da',\n",
              " 'em',\n",
              " 'um',\n",
              " 'para',\n",
              " 'com',\n",
              " 'não',\n",
              " 'uma',\n",
              " 'os',\n",
              " 'no',\n",
              " 'se',\n",
              " 'na',\n",
              " 'por',\n",
              " 'mais',\n",
              " 'as',\n",
              " 'dos',\n",
              " 'como',\n",
              " 'mas',\n",
              " 'ao',\n",
              " 'ele',\n",
              " 'das',\n",
              " 'à',\n",
              " 'seu',\n",
              " 'sua',\n",
              " 'ou',\n",
              " 'quando',\n",
              " 'muito',\n",
              " 'nos',\n",
              " 'já',\n",
              " 'eu',\n",
              " 'também',\n",
              " 'só',\n",
              " 'pelo',\n",
              " 'pela',\n",
              " 'até',\n",
              " 'isso',\n",
              " 'ela',\n",
              " 'entre',\n",
              " 'depois',\n",
              " 'sem',\n",
              " 'mesmo',\n",
              " 'aos',\n",
              " 'seus',\n",
              " 'quem',\n",
              " 'nas',\n",
              " 'me',\n",
              " 'esse',\n",
              " 'eles',\n",
              " 'você',\n",
              " 'essa',\n",
              " 'num',\n",
              " 'nem',\n",
              " 'suas',\n",
              " 'meu',\n",
              " 'às',\n",
              " 'minha',\n",
              " 'numa',\n",
              " 'pelos',\n",
              " 'elas',\n",
              " 'qual',\n",
              " 'nós',\n",
              " 'lhe',\n",
              " 'deles',\n",
              " 'essas',\n",
              " 'esses',\n",
              " 'pelas',\n",
              " 'este',\n",
              " 'dele',\n",
              " 'tu',\n",
              " 'te',\n",
              " 'vocês',\n",
              " 'vos',\n",
              " 'lhes',\n",
              " 'meus',\n",
              " 'minhas',\n",
              " 'teu',\n",
              " 'tua',\n",
              " 'teus',\n",
              " 'tuas',\n",
              " 'nosso',\n",
              " 'nossa',\n",
              " 'nossos',\n",
              " 'nossas',\n",
              " 'dela',\n",
              " 'delas',\n",
              " 'esta',\n",
              " 'estes',\n",
              " 'estas',\n",
              " 'aquele',\n",
              " 'aquela',\n",
              " 'aqueles',\n",
              " 'aquelas',\n",
              " 'isto',\n",
              " 'aquilo',\n",
              " 'estou',\n",
              " 'está',\n",
              " 'estamos',\n",
              " 'estão',\n",
              " 'estive',\n",
              " 'esteve',\n",
              " 'estivemos',\n",
              " 'estiveram',\n",
              " 'estava',\n",
              " 'estávamos',\n",
              " 'estavam',\n",
              " 'estivera',\n",
              " 'estivéramos',\n",
              " 'esteja',\n",
              " 'estejamos',\n",
              " 'estejam',\n",
              " 'estivesse',\n",
              " 'estivéssemos',\n",
              " 'estivessem',\n",
              " 'estiver',\n",
              " 'estivermos',\n",
              " 'estiverem',\n",
              " 'hei',\n",
              " 'há',\n",
              " 'havemos',\n",
              " 'hão',\n",
              " 'houve',\n",
              " 'houvemos',\n",
              " 'houveram',\n",
              " 'houvera',\n",
              " 'houvéramos',\n",
              " 'haja',\n",
              " 'hajamos',\n",
              " 'hajam',\n",
              " 'houvesse',\n",
              " 'houvéssemos',\n",
              " 'houvessem',\n",
              " 'houver',\n",
              " 'houvermos',\n",
              " 'houverem',\n",
              " 'houverei',\n",
              " 'houverá',\n",
              " 'houveremos',\n",
              " 'houverão',\n",
              " 'houveria',\n",
              " 'houveríamos',\n",
              " 'houveriam',\n",
              " 'sou',\n",
              " 'somos',\n",
              " 'são',\n",
              " 'era',\n",
              " 'éramos',\n",
              " 'eram',\n",
              " 'fui',\n",
              " 'foi',\n",
              " 'fomos',\n",
              " 'foram',\n",
              " 'fora',\n",
              " 'fôramos',\n",
              " 'seja',\n",
              " 'sejamos',\n",
              " 'sejam',\n",
              " 'fosse',\n",
              " 'fôssemos',\n",
              " 'fossem',\n",
              " 'for',\n",
              " 'formos',\n",
              " 'forem',\n",
              " 'serei',\n",
              " 'será',\n",
              " 'seremos',\n",
              " 'serão',\n",
              " 'seria',\n",
              " 'seríamos',\n",
              " 'seriam',\n",
              " 'tenho',\n",
              " 'tem',\n",
              " 'temos',\n",
              " 'tém',\n",
              " 'tinha',\n",
              " 'tínhamos',\n",
              " 'tinham',\n",
              " 'tive',\n",
              " 'teve',\n",
              " 'tivemos',\n",
              " 'tiveram',\n",
              " 'tivera',\n",
              " 'tivéramos',\n",
              " 'tenha',\n",
              " 'tenhamos',\n",
              " 'tenham',\n",
              " 'tivesse',\n",
              " 'tivéssemos',\n",
              " 'tivessem',\n",
              " 'tiver',\n",
              " 'tivermos',\n",
              " 'tiverem',\n",
              " 'terei',\n",
              " 'terá',\n",
              " 'teremos',\n",
              " 'terão',\n",
              " 'teria',\n",
              " 'teríamos',\n",
              " 'teriam']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXmTd7nZ6PPX",
        "outputId": "4025dda5-b5ba-4cb2-8cc9-c3adad96348e"
      },
      "source": [
        "nltk.download('rslp')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kyctWJv6W7C"
      },
      "source": [
        "stemmer = nltk.stem.RSLPStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I1DYI53k6dwb",
        "outputId": "95294205-bdc9-48b1-a9e5-827e76719773"
      },
      "source": [
        "stemmer.stem('copiar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'copi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mQISGYnx6mOv",
        "outputId": "2f176580-7cfe-47f7-88e9-ffff0ac7f815"
      },
      "source": [
        "stemmer.stem('casar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cas'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnOHfXx96u--",
        "outputId": "300b40eb-56b5-4570-eff2-846050b1fc9d"
      },
      "source": [
        "for words in palavras_tokenize:\n",
        "  print(stemmer.stem(words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exist\n",
            "teor\n",
            "que\n",
            "defend\n",
            "que\n",
            "ant\n",
            "da\n",
            "explor\n",
            "do\n",
            "impéri\n",
            "portugu\n",
            ",\n",
            "houv\n",
            "dua\n",
            "pass\n",
            "de\n",
            "espanhol\n",
            "pel\n",
            "litor\n",
            "da\n",
            "atual\n",
            "fortal\n",
            ".\n",
            "os\n",
            "naveg\n",
            "vicent\n",
            "yáñez\n",
            "pinzón\n",
            "e\n",
            "dieg\n",
            "de\n",
            "lep\n",
            "ter\n",
            "desembarc\n",
            "na\n",
            "cost\n",
            "cearens\n",
            "ant\n",
            "da\n",
            "viag\n",
            "de\n",
            "pedr\n",
            "álv\n",
            "cabr\n",
            "ao\n",
            "brasil\n",
            "em\n",
            "1500\n",
            ",\n",
            "emb\n",
            ",\n",
            "na\n",
            "vers\n",
            "tradic\n",
            ",\n",
            "o\n",
            "desembarqu\n",
            "de\n",
            "pinzón\n",
            "tenh\n",
            "se\n",
            "dad\n",
            "no\n",
            "cab\n",
            "de\n",
            "sant\n",
            "agost\n",
            "em\n",
            "pernambuc\n",
            ".\n",
            "pinzón\n",
            "ter\n",
            "cheg\n",
            "no\n",
            "cab\n",
            "que\n",
            "se\n",
            "acredit\n",
            "ser\n",
            "o\n",
            "mucurip\n",
            "e\n",
            "lep\n",
            "aport\n",
            "na\n",
            "barr\n",
            "do\n",
            "rio\n",
            "ce\n",
            ".\n",
            "tal\n",
            "descobert\n",
            "de\n",
            "territóri\n",
            "não\n",
            "pod\n",
            "ser\n",
            "ofici\n",
            "em\n",
            "decorr\n",
            "do\n",
            "trat\n",
            "de\n",
            "tordesilh\n",
            ",\n",
            "de\n",
            "1494\n",
            ".\n",
            "a\n",
            "cheg\n",
            "de\n",
            "pinzón\n",
            "ao\n",
            "mucurip\n",
            "foi\n",
            ",\n",
            "por\n",
            "vár\n",
            "vez\n",
            ",\n",
            "desconsider\n",
            "com\n",
            "um\n",
            "do\n",
            "possível\n",
            "pont\n",
            "de\n",
            "descobr\n",
            "pré-cabralin\n",
            "do\n",
            "país\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2g20k-Y7mDX"
      },
      "source": [
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNHrQ5QR7xOz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "32a0445b-d5dc-4454-8b37-56bbf7011fbd"
      },
      "source": [
        "tagger = joblib.load('POS_tagger_brill.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-7a0eac2b0f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'POS_tagger_brill.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'POS_tagger_brill.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzMjRpDM8EIN"
      },
      "source": [
        "phrase = 'O rato roeu a roupa do rei de Roma'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohCZp6v98H6o"
      },
      "source": [
        "phrase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2R3ECeS8KsI"
      },
      "source": [
        "tagger.tag(tokenize.word_tokenize(phrase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fIDEPoL86Qg"
      },
      "source": [
        "tagger.tag(tokenize.word_tokenize(sentence_tokenize[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYqaHNk8KGt8"
      },
      "source": [
        "import pandas as pd\n",
        "import altair as alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pShta01bK-Vy"
      },
      "source": [
        "url_df = 'belchior.csv'\n",
        "df = pd.read_csv(url_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whKr_k7tLOL3"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcWiDM6kMGZG"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OiJ0MWAMMRF"
      },
      "source": [
        "pts = alt.selection(type=\"interval\", encodings=[\"x\"])\n",
        "\n",
        "rowbars = alt.Chart(df).mark_bar().encode(\n",
        "    x='tamanho:Q',\n",
        "    y= alt.Y('titulo:O', sort = alt.EncodingSortField(field=\"tamanho\", order='descending')),   \n",
        "    color = 'maisTocada:O',\n",
        "    tooltip=['titulo', 'tamanho', 'keywords','letra']\n",
        ").transform_filter(\n",
        "    pts\n",
        ").properties(    \n",
        "    height=700,\n",
        "    width = 300,\n",
        "    title = 'Quantidade de palavras por música'\n",
        ")\n",
        "\n",
        "\n",
        "hist = alt.Chart(df).mark_bar().encode(\n",
        "    x = alt.X('hbin:N',title='Quantidade de palavras'),\n",
        "    y = alt.Y('count()',title='Contagem'),\n",
        "    tooltip = [alt.Tooltip('count():Q', title='Contagem de letras'),\n",
        "               alt.Tooltip('mbin:N', title='Quantidade de palavras')],\n",
        "    color = alt.condition(pts, alt.value(\"steelblue\"), alt.value(\"lightgray\"))\n",
        ").properties(\n",
        "    height = 320,\n",
        "    width = 320,\n",
        "    title = 'Histograma da quantidade de palavras por música'\n",
        ").add_selection(pts)\n",
        "\n",
        "hconcat = alt.hconcat(\n",
        "    rowbars,\n",
        "    hist,\n",
        "    data=df\n",
        ").transform_bin(\n",
        "    \"hbin\",\n",
        "    field=\"tamanho\",\n",
        "    bin=alt.Bin(maxbins=50)\n",
        ")\n",
        "\n",
        "#hconcat = rowbars | hist\n",
        "\n",
        "hconcat.save('1_tamanho_musicas.html')\n",
        "hconcat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo5g_-eRN1D3"
      },
      "source": [
        "url_df_freq = 'belchior_dist_freq.csv'\n",
        "df_freq = pd.read_csv(url_df_freq)\n",
        "df_freq = df_freq.sort_values(by='frequencia',ascending=False)\n",
        "df_freq.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE7m3-8SOG-w"
      },
      "source": [
        "df_freq50 = df_freq[0:50]\n",
        "\n",
        "wordfreq = alt.Chart(df_freq50).mark_bar().encode(\n",
        "    y='frequencia:Q',\n",
        "    x= alt.X('termo:O', sort = alt.EncodingSortField(field=\"frequencia\", order='descending')),\n",
        "    color = alt.value('steelblue'),\n",
        "    tooltip=[\n",
        "        'termo:O',\n",
        "        'frequencia:Q',\n",
        "        alt.Tooltip('musicas:O', title='Letras onde o termo ocorre')\n",
        "    ]\n",
        ").properties(    \n",
        "    height=300,\n",
        "    width = 850,\n",
        "    title = '50 termos mais frequentes'\n",
        ")\n",
        "\n",
        "wordfreq.save('2_frequencia_termos.html')\n",
        "wordfreq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RU9NzEVOb8S"
      },
      "source": [
        "url_sim = 'belchior_similaridade.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnFjv3JGOlU4"
      },
      "source": [
        "df_sim = pd.read_csv(url_sim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB5dcKbGOmnL"
      },
      "source": [
        "df_sim.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAGmqAYqO_Yz"
      },
      "source": [
        "source = df_sim.melt(id_vars=['titulo'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuEvOXLVPDQF"
      },
      "source": [
        "alt.data_transformers.disable_max_rows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWc4aCM9PFYf"
      },
      "source": [
        "matrix_sim = alt.Chart(source).mark_rect().encode(\n",
        "    x='titulo:O',\n",
        "    y='variable:O',\n",
        "    color=alt.Color('value:Q', scale=alt.Scale(scheme=\"inferno\")),\n",
        "    tooltip=[\n",
        "        alt.Tooltip('variable:O', title='Letra A'),\n",
        "        alt.Tooltip('titulo:O', title='Letra B'),\n",
        "        alt.Tooltip('value:Q', title='Similaridade'),\n",
        "    ]\n",
        ").properties(    \n",
        "    width = 600,\n",
        "    height= 600,    \n",
        "    title = 'Matriz de similaridade entre letras'\n",
        ")\n",
        "matrix_sim.save('4_similaridade_musicas.html')\n",
        "matrix_sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx5ceyS1P1Qj"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA1vnoVbP7Td"
      },
      "source": [
        "todas_keywords = ''\n",
        "for keyword in list(df['keywords']):\n",
        "    todas_keywords += keyword + ', '\n",
        "todas_keywords = todas_keywords[0:-2]\n",
        "todas_keywords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5opW5eODQLup"
      },
      "source": [
        "def normalize_text(txt):\n",
        "    txt = txt.lower()\n",
        "    txt = txt.replace(',','')\n",
        "    txt = txt.replace(';','')\n",
        "    txt = txt.replace('.','')\n",
        "    #txt = txt.replace('\\'','')\n",
        "    txt = txt.replace('(','')\n",
        "    txt = txt.replace(')','')\n",
        "    txt = txt.replace(':','')\n",
        "    txt = txt.replace('!','')\n",
        "    txt = txt.replace('?','')\n",
        "    txt = txt.replace(\"\\\\\",\"\")\n",
        "    txt = txt.replace(\"\\\"\",\"\")\n",
        "    txt = txt.replace(\"`\",\"\")\n",
        "    txt = txt.replace('</p>','')\n",
        "    return txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgX90_AMQavH"
      },
      "source": [
        "todas_letras = ' '.join(list(df['letra']))\n",
        "todas_letras = normalize_text(todas_letras)\n",
        "todas_letras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuaHSc4XQkgK"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riJP6ensQtpo"
      },
      "source": [
        "wordcloud = WordCloud(background_color=\"white\",width = 800, height = 600).generate(todas_letras)\n",
        "wordcloud.to_file(\"wordcloud.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scAOqMVlRNeM"
      },
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCc72l0ARmW1"
      },
      "source": [
        "brush = alt.selection(type='interval')\n",
        "\n",
        "pts = alt.selection(type=\"interval\", encodings=[\"x\"])\n",
        "\n",
        "points = alt.Chart(df).mark_circle().encode(\n",
        "    x='polaridade:Q',\n",
        "    y='subjetividade:Q',\n",
        "    color=alt.condition(brush, 'sentimento:N', alt.value('lightgray')),\n",
        "    tooltip=['titulo','polaridade','subjetividade','letra'],\n",
        "    size='tamanho:Q'\n",
        ").properties(    \n",
        "    title = 'Polaridade x Subjetividade'\n",
        ").add_selection(\n",
        "    brush\n",
        ").transform_filter(\n",
        "    pts\n",
        ")\n",
        "\n",
        "bars = alt.Chart(df).mark_bar().encode(\n",
        "    y=alt.Y('sentimento:N', title = 'Categorias'),\n",
        "    color='sentimento:N',\n",
        "    x=alt.X('count(sentimento):Q', title = 'Contagem'),\n",
        "    tooltip = [alt.Tooltip('count():Q', title='Contagem')],\n",
        ").properties(    \n",
        "    title = 'Categorias de Polaridade'\n",
        ").transform_filter(\n",
        "    brush\n",
        ").transform_filter(\n",
        "    pts\n",
        ")\n",
        "\n",
        "hist_pol = alt.Chart(df).mark_bar().encode(\n",
        "    x = alt.X(\"polaridade:Q\", bin=alt.Bin(maxbins=30),title = 'polaridade'),\n",
        "    y =alt.Y('count()',title='Contagem'),\n",
        "    tooltip = [alt.Tooltip('count():Q', title='Contagem')],\n",
        "    color = alt.condition(pts, 'sentimento:N', alt.value(\"lightgray\"))\n",
        ").properties(    \n",
        "    width = 320,\n",
        "    height = 200,\n",
        "    title = 'Histograma da polaridade'\n",
        ").add_selection(pts)\n",
        "\n",
        "\n",
        "hist_sub = alt.Chart(df).mark_bar().encode(\n",
        "    x = alt.X(\"subjetividade:Q\", bin=alt.Bin(maxbins=30),title = 'subjetividade'),\n",
        "    y =alt.Y('count()',title = 'Contagem'),\n",
        "    tooltip = [alt.Tooltip('count():Q', title='Contagem')],\n",
        "    color = alt.condition(pts, alt.value(\"lightblue\"), alt.value(\"lightgray\"))\n",
        ").properties(    \n",
        "    width = 320,\n",
        "    height = 200,\n",
        "    title = 'Histograma da subjetividade'\n",
        ").add_selection(pts)\n",
        "\n",
        "sent = alt.hconcat(\n",
        "    points & bars,\n",
        "    hist_pol & hist_sub,\n",
        "    data=df\n",
        ")\n",
        "\n",
        "pol = alt.Chart(df).mark_bar().encode(\n",
        "    y=\"polaridade:Q\",\n",
        "    x= alt.X(\"titulo:O\", sort = alt.EncodingSortField(field=\"polaridade\", order='descending')),\n",
        "    tooltip = ['titulo','polaridade','letra'],\n",
        "    color= 'sentimento'\n",
        ").properties(\n",
        "    width=800,\n",
        "    height = 300,\n",
        "    title = 'Polaridade das letras'\n",
        ").transform_filter(\n",
        "    pts\n",
        ")\n",
        "\n",
        "sent = ((points & bars) | (hist_sub & hist_pol)) & pol\n",
        "sent.properties(title = 'Análise de Sentimentos')\n",
        "sent.save('5_sentimentos.html')\n",
        "sent"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
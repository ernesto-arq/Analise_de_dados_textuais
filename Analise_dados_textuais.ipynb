{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analise_dados_textuais.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XdFtRWPl0i7"
      },
      "source": [
        "**Ernesto Gurgel Valente Neto**\n",
        "\n",
        "---\n",
        "# **Materia: Analise de Dados Textuais**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Prof: Wellington"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDGUFLs2llqC",
        "outputId": "278d61fe-5bf3-4e84-a786-d12e30d447c4"
      },
      "source": [
        "print('Importação de Pacotes')\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Importação de Pacotes\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giMVxl03mnne",
        "outputId": "eb76972b-aa1d-47c1-d541-399cac893a51"
      },
      "source": [
        "#Preparando toda a base de dados para leitura\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "from nltk import tokenize\n",
        "\n",
        "#Abrindo arquivos_Preparando\n",
        "review1 = open('review1.txt').read()\n",
        "#review1_tokenize = tokenize.word_tokenize(review1, language='english')\n",
        "#review1_lower = set(word.lower() for word in review1_tokenize if word.isalpha())\n",
        "#review1_tag = nltk.pos_tag(review1_lower)\n",
        "\n",
        "review2 = open('review2.txt').read()\n",
        "#review2_tokenize = tokenize.word_tokenize(review2, language='english')\n",
        "#review2_lower = set(word.lower() for word in review2_tokenize if word.isalpha())\n",
        "#review2_tag = nltk.pos_tag(review2_lower)\n",
        "\n",
        "review3 = open('review3.txt').read()\n",
        "#review3_tokenize = tokenize.word_tokenize(review3, language='english')\n",
        "#review3_lower = set(word.lower() for word in review3_tokenize if word.isalpha())\n",
        "#review3_tag = nltk.pos_tag(review3_lower)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnS3ALIxnA4f",
        "outputId": "8e732fe1-0d29-43f9-88d4-3c8206dfc329"
      },
      "source": [
        "print(\"Review 1:\\n\", review1)\n",
        "#print(\"Review 1:\\n\", review1_tag)\n",
        "#print(\"Review 1:\\n\", review1_lower)\n",
        "print(\"Review 2:\\n\", review2)\n",
        "#print(\"Review 2:\\n\", review2_tag)\n",
        "#print(\"Review 2:\\n\", review2_lower)\n",
        "print(\"Review 3:\\n\", review2)\n",
        "#print(\"Review 3:\\n\", review3_tag)\n",
        "#print(\"Review 3:\\n\", review3_lower)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review 1:\n",
            " \"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70's, they discover the criminal and a net of power and money to cover the murder.\"Murder in Greenwich\"\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization.\n",
            "Review 2:\n",
            " hi for all the people who have seen this wonderful movie im sure thet you would have liked it as much as i. i love the songs once you have seen the show you can sing along as though you are part of the show singing and dancing . dancing and singing. the song ONE is an all time fave musical song too and the strutters at the end with the mirror its so oh you have to watch this one.\n",
            "Review 3:\n",
            " hi for all the people who have seen this wonderful movie im sure thet you would have liked it as much as i. i love the songs once you have seen the show you can sing along as though you are part of the show singing and dancing . dancing and singing. the song ONE is an all time fave musical song too and the strutters at the end with the mirror its so oh you have to watch this one.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_pfeVfCurB1"
      },
      "source": [
        "1) Utilizando as técnicas aprendidas sobre análise de sentimentos\n",
        "defina a polaridade dos arquivos presentes na pasta “Lista 05”.\n",
        "Utiliza os arquivos positive_words.txt e negative_words.text\n",
        "presentes na pasta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sU2R5u0oqHJ"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "negative = []\n",
        "positive = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mHEYfWHpUy6"
      },
      "source": [
        "with open(\"negative_words.csv\", \"r\") as file:\n",
        "  reader = csv.reader(file)\n",
        "  for row in reader:\n",
        "        negative.append(row)\n",
        "        \n",
        "with open(\"positive_words.csv\", \"r\") as file:\n",
        "  reader = csv.reader(file)\n",
        "  for row in reader:\n",
        "        positive.append(row)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F52ubs93psLh",
        "outputId": "fd022f18-5232-4265-d944-49cba2e93f3f"
      },
      "source": [
        "print(\"Palavras Negativas:\", negative)\n",
        "print(\"Palavras Positivas: \",positive)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Palavras Negativas: [['abysmal'], ['adverse'], ['alarming'], ['angry'], ['annoy'], ['annoying'], ['anxious'], ['apathy'], ['appalling'], ['atrocious'], ['awful'], ['bad'], ['banal'], ['barbed'], ['belligerent'], ['bemoan'], ['beneath'], ['boring'], ['broken'], ['callous'], [\"can't\"], ['clumsy'], ['coarse'], ['cold'], ['cold-hearted'], ['collapse'], ['confused'], ['contradictory'], ['contrary'], ['corrosive'], ['corrupt'], ['crazy'], ['creepy'], ['criminal'], ['cruel'], ['cry'], ['cutting'], ['dead'], ['decaying'], ['damage'], ['damaging'], ['dastardly'], ['deplorable'], ['depressed'], ['deprived'], ['deformed'], ['deny'], ['despicable'], ['detrimental'], ['dirty'], ['disappoint'], ['disappointed'], ['disease'], ['disgusting'], ['disheveled'], ['dishonest'], ['dishonorable'], ['dismal'], ['distress'], ['dont'], [\"don't\"], ['dreadful'], ['dreary'], ['enraged'], ['eroding'], ['evil'], ['fail'], ['faulty'], ['fear'], ['feeble'], ['fight'], ['filthy'], ['foul'], ['frighten'], ['frightful'], ['frustration'], ['fuck'], ['gawky'], ['ghastly'], ['grave'], ['greed'], ['grim'], ['grimace'], ['gross'], ['grotesque'], ['gruesome'], ['guilty'], ['haggard'], ['hard'], ['hard-hearted'], ['harmful'], ['hate'], ['hideous'], ['homely'], ['horrendous'], ['horrible'], ['hostile'], ['hurt'], ['hurtful'], ['icky'], ['ignore'], ['ignorant'], ['ill'], ['immature'], ['imperfect'], ['impossible'], ['inane'], ['inelegant'], ['infernal'], ['injure'], ['injurious'], ['insane'], ['insidious'], ['insipid'], ['issue'], ['issues'], ['jealous'], ['junky'], ['lose'], ['lousy'], ['lumpy'], ['malicious'], ['mean'], ['menacing'], ['messy'], ['misshapen'], ['missing'], ['misunderstood'], ['moan'], ['moldy'], ['monstrous'], ['naive'], ['nasty'], ['naughty'], ['negate'], ['negative'], ['never'], ['no'], ['nobody'], ['nondescript'], ['nonsense'], ['not'], ['noxious'], ['objectionable'], ['odious'], ['offensive'], ['old'], ['oppressive'], ['pain'], ['perturb'], ['pessimistic'], ['petty'], ['plain'], ['poisonous'], ['poop'], ['poor'], ['prejudice'], ['problem'], ['questionable'], ['quirky'], ['quit'], ['reject'], ['renege'], ['repellant'], ['reptilian'], ['repulsive'], ['repugnant'], ['revenge'], ['revolting'], ['rocky'], ['rotten'], ['rude'], ['ruthless'], ['sad'], ['savage'], ['scare'], ['scary'], ['scream'], ['severe'], ['shit'], ['shoddy'], ['shocking'], ['sick'], ['sickening'], ['sinister'], ['slimy'], ['smelly'], ['sobbing'], ['sorry'], ['spiteful'], ['sticky'], ['stinky'], ['stormy'], ['stressful'], ['stuck'], ['stupid'], ['substandard'], ['suck'], ['sucks'], ['suspect'], ['suspicious'], ['tense'], ['terrible'], ['terrifying'], ['threatening'], ['ugly'], ['undermine'], ['unfair'], ['unfavorable'], ['unhappy'], ['unhealthy'], ['uninspired'], ['unjust'], ['unlucky'], ['unpleasant'], ['upset'], ['unsatisfactory'], ['unsightly'], ['untoward'], ['unwanted'], ['unwelcome'], ['unwholesome'], ['unwieldy'], ['unwise'], ['upset'], ['vice'], ['vicious'], ['vile'], ['villainous'], ['vindictive'], ['wary'], ['weary'], ['wicked'], ['woeful'], ['worse'], ['worst'], ['worthless'], ['wound'], ['yell'], ['yucky'], ['zero']]\n",
            "Palavras Positivas:  [['absolutely'], ['adorable'], ['accepted'], ['acclaimed'], ['accomplish'], ['accomplishment'], ['achievement'], ['action'], ['active'], ['admire'], ['adventure'], ['affirmative'], ['affluent'], ['agree'], ['agreeable'], ['amazing'], ['angelic'], ['appealing'], ['approve'], ['aptitude'], ['attractive'], ['awesome'], ['beaming'], ['beautiful'], ['believe'], ['beneficial'], ['bliss'], ['bountiful'], ['bounty'], ['brave'], ['bravo'], ['brilliant'], ['bubbly'], ['calm'], ['celebrated'], ['certain'], ['champ'], ['champion'], ['charming'], ['cheery'], ['choice'], ['classic'], ['classical'], ['clean'], ['commend'], ['composed'], ['congratulation'], ['constant'], ['cool'], ['courageous'], ['creative'], ['cute'], ['dazzling'], ['delight'], ['delightful'], ['distinguished'], ['divine'], ['earnest'], ['easy'], ['ecstatic'], ['effective'], ['effervescent'], ['efficient'], ['effortless'], ['electrifying'], ['elegant'], ['enchanting'], ['encouraging'], ['endorsed'], ['energetic'], ['energized'], ['engaging'], ['enthusiastic'], ['essential'], ['esteemed'], ['ethical'], ['excellent'], ['exceptional'], ['exciting'], ['exquisite'], ['fabulous'], ['fair'], ['familiar'], ['famous'], ['fantastic'], ['favorable'], ['fetching'], ['fine'], ['fitting'], ['flourishing'], ['fortunate'], ['free'], ['fresh'], ['friendly'], ['fun'], ['funny'], ['generous'], ['genius'], ['genuine'], ['giving'], ['glamorous'], ['glowing'], ['good'], ['gorgeous'], ['graceful'], ['great'], ['green'], ['grin'], ['growing'], ['handsome'], ['happy'], ['harmonious'], ['healing'], ['healthy'], ['hearty'], ['heavenly'], ['honest'], ['honorable'], ['honored'], ['hug'], ['idea'], ['ideal'], ['imaginative'], ['imagine'], ['impressive'], ['independent'], ['innovate'], ['innovative'], ['instant'], ['instantaneous'], ['instinctive'], ['intuitive'], ['intellectual'], ['intelligent'], ['inventive'], ['jovial'], ['joy'], ['jubilant'], ['keen'], ['kind'], ['knowing'], ['knowledgeable'], ['laugh'], ['legendary'], ['light'], ['like'], ['learned'], ['lively'], ['love'], ['lovely'], ['lucid'], ['lucky'], ['luminous'], ['marvelous'], ['masterful'], ['meaningful'], ['merit'], ['meritorious'], ['miraculous'], ['motivating'], ['moving'], ['natural'], ['nice'], ['novel'], ['now'], ['nurturing'], ['nutritious'], ['okay'], ['one'], ['one-hundred percent'], ['open'], ['optimistic'], ['paradise'], ['perfect'], ['phenomenal'], ['pleasurable'], ['plentiful'], ['pleasant'], ['poised'], ['polished'], ['popular'], ['positive'], ['powerful'], ['prepared'], ['pretty'], ['principled'], ['productive'], ['progress'], ['prominent'], ['protected'], ['proud'], ['quality'], ['quick'], ['quiet'], ['ready'], ['reassuring'], ['recommend'], ['refined'], ['refreshing'], ['rejoice'], ['reliable'], ['remarkable'], ['resounding'], ['respected'], ['restored'], ['reward'], ['rewarding'], ['right'], ['robust'], ['safe'], ['satisfactory'], ['secure'], ['seemly'], ['simple'], ['skilled'], ['skillful'], ['smile'], ['soulful'], ['sparkling'], ['special'], ['spirited'], ['spiritual'], ['stirring'], ['stupendous'], ['stunning'], ['success'], ['successful'], ['sunny'], ['super'], ['superb'], ['supporting'], ['surprising'], ['terrific'], ['thorough'], ['thrilling'], ['thriving'], ['tops'], ['tranquil'], ['transforming'], ['transformative'], ['trusting'], ['truthful'], ['unreal'], ['unwavering'], ['up'], ['upbeat'], ['upright'], ['upstanding'], ['valued'], ['very'], ['vibrant'], ['victorious'], ['victory'], ['vigorous'], ['virtuous'], ['vital'], ['vivacious'], ['wealthy'], ['welcome'], ['well'], ['whole'], ['wholesome'], ['willing'], ['wonderful'], ['wondrous'], ['worthy'], ['wow'], ['yes'], ['yummy'], ['zeal'], ['zealous']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkFIhRk1qOzA"
      },
      "source": [
        "# **Função de Analise de Sentimentos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oREzDoDmqSW-"
      },
      "source": [
        "def sentiment(text):\n",
        "    temp = [] #\n",
        "    text_sent = nltk.sent_tokenize(text)\n",
        "    for sentence in text_sent:\n",
        "        n_count = 0\n",
        "        p_count = 0\n",
        "        sent_words = nltk.word_tokenize(sentence)\n",
        "        for word in sent_words:\n",
        "            for item in positive:\n",
        "                if(word == item[0]):\n",
        "                    p_count +=1\n",
        "            for item in negative:\n",
        "                if(word == item[0]):\n",
        "                    n_count +=1\n",
        "        if(p_count > 0 and n_count == 0):\n",
        "            temp.append(1)\n",
        "        elif(n_count%2 > 0):\n",
        "            temp.append(-1)\n",
        "        elif(n_count%2 ==0 and n_count > 0):\n",
        "            temp.append(1)\n",
        "        else:\n",
        "            temp.append(0)\n",
        "    return temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a69hNfYMqYhO",
        "outputId": "ef7d464c-135e-4e20-ae76-aa2492005072"
      },
      "source": [
        "#[Caso 1, 1 Positivo], [Caso 2, -1 Negativo], [Caso 3, 0 Neutro]\n",
        "print(\"Analise de Caso 1: \", sentiment(review1))\n",
        "print(\"Analise de Caso 2: \", sentiment(review2))\n",
        "print(\"Analise de Caso 3: \", sentiment(review3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analise de Caso 1:  [0, 0, 0, 0, 1, -1, 1, -1, 0]\n",
            "Analise de Caso 2:  [1, 0, 1]\n",
            "Analise de Caso 3:  [1, 0, 1, 1, 0, -1, 0, 0, 0, -1, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
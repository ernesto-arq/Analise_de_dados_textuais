# -*- coding: utf-8 -*-
"""Analise_dados_textuais_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iHtOvQw-F2JQuRwo2WrZ705GpDPtx6nZ

# **Ernesto Gurgel Valente Neto**

---
# **Materia: Analise de Dados Textuais**


---

Prof: Wellington
"""

print('Importação de Pacotes')
import nltk
import re
nltk.download('gutenberg')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')

nltk.corpus.gutenberg.fileids()

"""# 1) Para o corpus “shakespeare-caesar.txt”, usando expressões
regulares responda os seguintes itens: **texto em negrito**

"""

caesar = nltk.corpus.gutenberg.words('shakespeare-caesar.txt')

"""# **a) Quantidades de palavras que terminam com “r”;**

"""

#procura dados casados
#re.fullmatch()
#buscar determinado padrao ou contexto
#re.search()

lista_word_r = []
for word in caesar:
  if re.search("r$",word):
    lista_word_r.append(word)

#lista_word_r

print('Tamanho da Quantidade de palavras que terminam com R:', len(lista_word_r))

"""# **b) Quantidade de palavras com 5 letras;**"""

lista_word_5 = []
for word in caesar:
  if re.search("^.....",word):
    lista_word_5.append(word)

#lista_word_5

print('Tamanho da Quantidade de palavras que terminam com 5 letras:', len(lista_word_5))

"""# **c) Quantidade de vezes que “err” ocorre no corpus;**"""

lista_word_err = []
for word in caesar:
  if re.search("err",word):
    lista_word_err.append(word)

#lista_word_err

print('Tamanho da Quantidade de palavras que terminam com err:', len(lista_word_err))

"""# **d) Quantidade de vezes que “are” ocorre no corpus para as palavras com 5 ou mais caracteres.**"""

lista_word_are1 = []
for word in caesar:
  if re.search("are..",word):
    lista_word_are1.append(word)
lista_word_are2 = []
for word in caesar:
  if re.search(".are.",word):
    lista_word_are2.append(word)
lista_word_are3 = []
for word in caesar:
  #sinal + Check if the string contains followed by 1 or more "x" characters:
  if re.search("^.*are.*$",word):
    lista_word_are3.append(word)

x1 = len(lista_word_are1)
x2 = len(lista_word_are2)
x3 = len(lista_word_are3)

#lista_word_are1
#lista_word_are2
#lista_word_are3

print('Tamanho da Quantidade de palavras que terminam com are com 5 ou mais palavras:', x1+x2+x3)

"""# **2) Em relação do corpus “shakespeare-hamlet.txt”, faça as seguintes atividades:**

# **a) Normalize o corpus (Retire os números e deixe todas as palavras minúsculas);**
"""

#normalizando todas as sentenças em letra minuscula
minusculas = set(word.lower() for word in caesar if word.isalpha())
#toda palavra tem pelo menos 2 letras, isso tbm retira ",", "[", "!", "?", "." "outros caracteres", podem existir numeros de 2ddigitos ou mais, para isso temos a condição "isinstance(word, int) == False"
lista_sem_num = []
for word in minusculas:
  if (isinstance(word, int) == False):
      if re.search("..", word):
        lista_sem_num.append(word)

#minusculas
#lista_sem_num
print("Retire os números e deixe todas as palavras minúsculas: ", lista_sem_num)

"""# **b) Aplique o lematizador em todas as palavras do corpus;**"""

import nltk 
nltk.download('wordnet') 
from nltk.stem import WordNetLemmatizer

# Create WordNetLemmatizer object 
wnl = WordNetLemmatizer() 
  
# single word lemmatization examples 
listLematizar = nltk.corpus.gutenberg.words('shakespeare-caesar.txt')
listLematizar = set(word.lower() for word in listLematizar if word.isalpha())

#for words in listLematizar: 
    #print("Palavra não Lematizada: %%%%", words + " %%%% Palavra Lematiazada: " + wnl.lemmatize(words))

texto = str(listLematizar).strip('[]')
list2 = nltk.word_tokenize(texto)
lemmatized_string = ' '.join([wnl.lemmatize(words) for words in list2]) 

print("Lista Não Lematizada: ", list2) 
print("Lista Lematizada: ", lemmatized_string)

#Armazenador do lematizador
LemaSalvarDados = []
for word in list2:
    LemaSalvarDados.append(wnl.lemmatize(word))
print(LemaSalvarDados)

"""# **c) Aplique o tokenizador em todas as sentenças do corpus;**"""

tokens = [nltk.word_tokenize(str(comment)) for comment in minusculas]
print("tokenizador em todas as sentenças do corpus: ", tokens)

"""# **d) Aplique os pos tagger e responda a quantidade de adjetivos existem no corpus; Dica a tag de adjetivo é “JJ”**"""

texto = nltk.corpus.gutenberg.words('shakespeare-caesar.txt')
texto = set(word.lower() for word in texto if word.isalpha())
texto = [nltk.word_tokenize(str(comment)) for comment in texto]
texto = str(texto).strip('[]')
text_tag = nltk.pos_tag(nltk.word_tokenize(texto))

ListaPP1 = [word[1] for word in text_tag if word[1] == "JJ"]
print('quantidade de adjetivos existem no corpus:', len(ListaPP1))
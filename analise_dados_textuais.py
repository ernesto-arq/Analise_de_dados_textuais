# -*- coding: utf-8 -*-
"""Analise_dados_textuais.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o2p-NLe5jYG-MkCj4TCa2ELwwiTsServ

**Ernesto Gurgel Valente Neto**

---
# **Materia: Analise de Dados Textuais**


---

Prof: Wellington
"""

print('Importação de Pacotes')
import nltk
import re
nltk.download('gutenberg')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')

#Preparando toda a base de dados para leitura
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')
from nltk import tokenize

#Abrindo arquivos_Preparando
review1 = open('review1.txt').read()
#review1_tokenize = tokenize.word_tokenize(review1, language='english')
#review1_lower = set(word.lower() for word in review1_tokenize if word.isalpha())
#review1_tag = nltk.pos_tag(review1_lower)

review2 = open('review2.txt').read()
#review2_tokenize = tokenize.word_tokenize(review2, language='english')
#review2_lower = set(word.lower() for word in review2_tokenize if word.isalpha())
#review2_tag = nltk.pos_tag(review2_lower)

review3 = open('review3.txt').read()
#review3_tokenize = tokenize.word_tokenize(review3, language='english')
#review3_lower = set(word.lower() for word in review3_tokenize if word.isalpha())
#review3_tag = nltk.pos_tag(review3_lower)

print("Review 1:\n", review1)
#print("Review 1:\n", review1_tag)
#print("Review 1:\n", review1_lower)
print("Review 2:\n", review2)
#print("Review 2:\n", review2_tag)
#print("Review 2:\n", review2_lower)
print("Review 3:\n", review2)
#print("Review 3:\n", review3_tag)
#print("Review 3:\n", review3_lower)

"""1) Utilizando as técnicas aprendidas sobre análise de sentimentos
defina a polaridade dos arquivos presentes na pasta “Lista 05”.
Utiliza os arquivos positive_words.txt e negative_words.text
presentes na pasta.
"""

import numpy as np
import csv
negative = []
positive = []

with open("negative_words.csv", "r") as file:
  reader = csv.reader(file)
  for row in reader:
        negative.append(row)
        
with open("positive_words.csv", "r") as file:
  reader = csv.reader(file)
  for row in reader:
        positive.append(row)

print("Palavras Negativas:", negative)
print("Palavras Positivas: ",positive)

"""# **Função de Analise de Sentimentos**"""

def sentiment(text):
    temp = [] #
    text_sent = nltk.sent_tokenize(text)
    for sentence in text_sent:
        n_count = 0
        p_count = 0
        sent_words = nltk.word_tokenize(sentence)
        for word in sent_words:
            for item in positive:
                if(word == item[0]):
                    p_count +=1
            for item in negative:
                if(word == item[0]):
                    n_count +=1
        if(p_count > 0 and n_count == 0):
            temp.append(1)
        elif(n_count%2 > 0):
            temp.append(-1)
        elif(n_count%2 ==0 and n_count > 0):
            temp.append(1)
        else:
            temp.append(0)
    return temp

#[Caso 1, 1 Positivo], [Caso 2, -1 Negativo], [Caso 3, 0 Neutro]
print("Analise de Caso 1: ", sentiment(review1))
print("Analise de Caso 2: ", sentiment(review2))
print("Analise de Caso 3: ", sentiment(review3))